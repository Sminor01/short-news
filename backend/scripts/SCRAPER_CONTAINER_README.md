# üê≥ News Scraper Container

–û—Ç–¥–µ–ª—å–Ω—ã–π Docker –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞ –∏ —Å–±–æ—Ä–∞ –Ω–æ–≤–æ—Å—Ç–µ–π.

## üìã –û–ø–∏—Å–∞–Ω–∏–µ

–ö–æ–Ω—Ç–µ–π–Ω–µ—Ä `news-scraper` –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–ø—É—Å–∫–∞–µ—Ç —Å–∫—Ä–∞–ø–∏–Ω–≥ –Ω–æ–≤–æ—Å—Ç–µ–π –∫–∞–∂–¥—ã–π —á–∞—Å –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö.

## ‚è∞ –†–∞—Å–ø–∏—Å–∞–Ω–∏–µ

- **–ö–∞–∂–¥—ã–π —á–∞—Å**: –ó–∞–ø—É—Å–∫ `scrape_all_companies.py` (–≤ 00 –º–∏–Ω—É—Ç –∫–∞–∂–¥–æ–≥–æ —á–∞—Å–∞)
- **–ö–∞–∂–¥—ã–µ 6 —á–∞—Å–æ–≤**: –ó–∞–ø—É—Å–∫ `populate_news.py` (–≤ 00:00, 06:00, 12:00, 18:00)
- **–ï–∂–µ–Ω–µ–¥–µ–ª—å–Ω–æ**: –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –ª–æ–≥–æ–≤ (–∫–∞–∂–¥–æ–µ –≤–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ –≤ 02:00)

## üöÄ –ó–∞–ø—É—Å–∫

### –ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö —Å–µ—Ä–≤–∏—Å–æ–≤ (–≤–∫–ª—é—á–∞—è —Å–∫—Ä–∞–ø–µ—Ä):
```bash
docker-compose up -d
```

### –ó–∞–ø—É—Å–∫ —Ç–æ–ª—å–∫–æ —Å–∫—Ä–∞–ø–µ—Ä–∞:
```bash
docker-compose up news-scraper -d
```

### –û–¥–Ω–æ—Ä–∞–∑–æ–≤—ã–π –∑–∞–ø—É—Å–∫ —Å–∫—Ä–∞–ø–µ—Ä–∞:
```bash
docker-compose run --rm news-scraper /usr/local/bin/run-scraper.sh
```

## üìä –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥

### –ü—Ä–æ—Å–º–æ—Ç—Ä –ª–æ–≥–æ–≤ —Å–∫—Ä–∞–ø–µ—Ä–∞:
```bash
# –õ–æ–≥–∏ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞
docker-compose logs -f news-scraper

# –õ–æ–≥–∏ —Å–∫—Ä–∞–ø–∏–Ω–≥–∞
docker-compose exec news-scraper tail -f /var/log/scraper.log
```

### –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞ cron:
```bash
docker-compose exec news-scraper crontab -l
```

### –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ—Ü–µ—Å—Å–æ–≤:
```bash
docker-compose exec news-scraper ps aux | grep cron
```

## üîß –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ

### –û—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å–∫—Ä–∞–ø–µ—Ä–∞:
```bash
docker-compose stop news-scraper
```

### –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫ —Å–∫—Ä–∞–ø–µ—Ä–∞:
```bash
docker-compose restart news-scraper
```

### –ü–µ—Ä–µ—Å–±–æ—Ä–∫–∞ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞:
```bash
docker-compose build news-scraper
docker-compose up news-scraper -d
```

## üìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ñ–∞–π–ª–æ–≤

```
backend/
‚îú‚îÄ‚îÄ Dockerfile.scraper          # Dockerfile –¥–ª—è –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞ —Å–∫—Ä–∞–ø–µ—Ä–∞
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ scraper-entrypoint.sh   # Entrypoint —Å–∫—Ä–∏–ø—Ç
‚îÇ   ‚îú‚îÄ‚îÄ scraper-cron           # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è cron jobs
‚îÇ   ‚îú‚îÄ‚îÄ run-scraper.sh         # –°–∫—Ä–∏–ø—Ç –¥–ª—è –∑–∞–ø—É—Å–∫–∞ —Å–∫—Ä–∞–ø–µ—Ä–∞
‚îÇ   ‚îî‚îÄ‚îÄ scrape_all_companies.py # –û—Å–Ω–æ–≤–Ω–æ–π —Å–∫—Ä–∏–ø—Ç —Å–∫—Ä–∞–ø–∏–Ω–≥–∞
```

## üêõ –û—Ç–ª–∞–¥–∫–∞

### –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î:
```bash
docker-compose exec news-scraper python -c "
import asyncio
from app.core.database import AsyncSessionLocal

async def test_db():
    async with AsyncSessionLocal() as db:
        await db.execute('SELECT 1')
    print('‚úÖ Database connection OK')

asyncio.run(test_db())
"
```

### –†—É—á–Ω–æ–π –∑–∞–ø—É—Å–∫ —Å–∫—Ä–∞–ø–µ—Ä–∞:
```bash
docker-compose exec news-scraper python scripts/scrape_all_companies.py
```

### –ü—Ä–æ–≤–µ—Ä–∫–∞ cron jobs:
```bash
docker-compose exec news-scraper cat /etc/cron.d/scraper-cron
```

## üìà –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å

- –ö–æ–Ω—Ç–µ–π–Ω–µ—Ä –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫ –ø—Ä–∏ —Å–±–æ—è—Ö (`restart: unless-stopped`)
- Health check –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è
- –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Å–µ—Ö –æ–ø–µ—Ä–∞—Ü–∏–π

## üîí –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å

- –ö–æ–Ω—Ç–µ–π–Ω–µ—Ä —Ä–∞–±–æ—Ç–∞–µ—Ç —Å —Ç–µ–º–∏ –∂–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –æ–∫—Ä—É–∂–µ–Ω–∏—è, —á—Ç–æ –∏ –æ—Å–Ω–æ–≤–Ω–æ–π backend
- –î–æ—Å—Ç—É–ø –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö —Ç–æ–ª—å–∫–æ –¥–ª—è —á—Ç–µ–Ω–∏—è/–∑–∞–ø–∏—Å–∏ –Ω–æ–≤–æ—Å—Ç–µ–π
- –ò–∑–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å—Ä–µ–¥–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è

## üìù –õ–æ–≥–∏

–í—Å–µ –ª–æ–≥–∏ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –≤:
- `/var/log/scraper.log` - –≤–Ω—É—Ç—Ä–∏ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞
- `docker-compose logs news-scraper` - –ª–æ–≥–∏ Docker

–§–æ—Ä–º–∞—Ç –ª–æ–≥–æ–≤:
```
2024-01-15 10:00:01: Starting scheduled news scraping...
2024-01-15 10:00:02: Running scrape_all_companies.py...
2024-01-15 10:05:30: ‚úÖ scrape_all_companies.py completed successfully
2024-01-15 10:05:31: Scheduled scraping completed successfully
```



